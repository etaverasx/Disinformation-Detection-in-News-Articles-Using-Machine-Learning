{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20462fba-2060-4d71-be1b-3c0b75329d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For text processing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# For data splitting and balancing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# For modeling\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Step 2: Load the cleaned dataset\n",
    "file_path = 'news_articles-1.xlsx'  # If in same directory as your notebook\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Step 3: Quick check\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"First few rows:\")\n",
    "display(df.head())\n",
    "# Step 4: Prepare feature (X) and label (y)\n",
    "X = df['text_without_stopwords']\n",
    "y = df['label'].map({'Fake': 0, 'Real': 1})  # Convert labels to binary: 0 = Fake, 1 = Real\n",
    "\n",
    "# Check class balance\n",
    "print(\"Label distribution:\")\n",
    "print(y.value_counts(normalize=True))\n",
    "# Step 5: Pie chart to show label distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count label frequencies\n",
    "label_counts = y.value_counts()\n",
    "labels = ['Fake News', 'Real News']\n",
    "sizes = label_counts.values\n",
    "colors = ['#ff9999','#66b3ff']\n",
    "explode = (0.05, 0)  # Slightly \"explode\" the first slice (Fake News)\n",
    "\n",
    "# Plot pie chart\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140, colors=colors, explode=explode, shadow=True)\n",
    "plt.title('Fake vs. Real News Distribution')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures the pie is circular\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bab6e0-a323-45a6-ac75-c13397439b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm required column\n",
    "assert 'title_without_stopwords' in df.columns, \"Missing 'title_without_stopwords' column\"\n",
    "\n",
    "# 3. Define Experiment Runner Function\n",
    "def run_title_split_experiment(model_name, test_size, ngram_range, min_df, max_features):\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        stop_words='english',\n",
    "        min_df=min_df,\n",
    "        ngram_range=ngram_range,\n",
    "        max_features=max_features\n",
    "    )\n",
    "    \n",
    "    X = tfidf_vectorizer.fit_transform(df['title_without_stopwords'].astype(str))\n",
    "    y = df['label'].map({'Fake': 0, 'Real': 1})  # Binary encoding\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    if model_name == 'Decision Tree':\n",
    "        model = DecisionTreeClassifier(random_state=42)\n",
    "    elif model_name == 'k-NN':\n",
    "        model = KNeighborsClassifier()\n",
    "    elif model_name == 'Multinomial NB':\n",
    "        model = MultinomialNB()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Test Size': test_size,\n",
    "        'Accuracy': round(accuracy_score(y_test, y_pred), 4),\n",
    "        'Precision': round(precision_score(y_test, y_pred), 4),\n",
    "        'Recall': round(recall_score(y_test, y_pred), 4),\n",
    "        'F1 Score': round(f1_score(y_test, y_pred), 4),\n",
    "        'Min DF': min_df,\n",
    "        'N-Gram Range': ngram_range,\n",
    "        'Max Features': max_features\n",
    "    }\n",
    "\n",
    "# 4. Define Experiment Plan\n",
    "title_split_experiment_plan = [\n",
    "    # Decision Tree\n",
    "    ('Decision Tree', 0.2, (1, 1), 5, 1000),\n",
    "    ('Decision Tree', 0.3, (1, 2), 10, 3000),\n",
    "    ('Decision Tree', 0.4, (1, 3), 15, 2000),\n",
    "    \n",
    "    # k-NN\n",
    "    ('k-NN', 0.2, (1, 1), 5, 1000),\n",
    "    ('k-NN', 0.3, (1, 2), 10, 3000),\n",
    "    ('k-NN', 0.4, (1, 3), 15, 2000),\n",
    "    \n",
    "    # Multinomial NB\n",
    "    ('Multinomial NB', 0.2, (1, 1), 5, 1000),\n",
    "    ('Multinomial NB', 0.3, (1, 2), 10, 3000),\n",
    "    ('Multinomial NB', 0.4, (1, 3), 15, 2000)\n",
    "]\n",
    "\n",
    "\n",
    "# 5. Run Experiments\n",
    "\n",
    "title_split_results = []\n",
    "\n",
    "for model_name, test_size, ngram_range, min_df, max_features in title_split_experiment_plan:\n",
    "    result = run_title_split_experiment(\n",
    "        model_name, test_size, ngram_range, min_df, max_features\n",
    "    )\n",
    "    title_split_results.append(result)\n",
    "\n",
    "# 6. Display Clean Results Table\n",
    "\n",
    "results_df = pd.DataFrame(title_split_results)\n",
    "results_df = results_df.sort_values(by=['Model', 'Test Size'])\n",
    "\n",
    "# Ensure all columns display in one row\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 160)\n",
    "\n",
    "# Print clean table\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c8d6d8-9ffa-434e-9bb4-56fc0311a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 2. Confirm Required Column\n",
    "assert 'title_without_stopwords' in df.columns, \"Missing 'title_without_stopwords' column\"\n",
    "\n",
    "# 3. Define Experiment Runner Function (with SMOTE and Confusion Matrix)\n",
    "def run_title_split_experiment(model_name, test_size, ngram_range, min_df, max_features):\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        stop_words='english',\n",
    "        min_df=min_df,\n",
    "        ngram_range=ngram_range,\n",
    "        max_features=max_features\n",
    "    )\n",
    "    \n",
    "    X = tfidf_vectorizer.fit_transform(df['title_without_stopwords'].astype(str))\n",
    "    y = df['label'].map({'Fake': 0, 'Real': 1})  # Binary encoding\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Apply SMOTE to training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Select model\n",
    "    if model_name == 'Decision Tree':\n",
    "        model = DecisionTreeClassifier(random_state=42)\n",
    "    elif model_name == 'k-NN':\n",
    "        model = KNeighborsClassifier()\n",
    "    elif model_name == 'Multinomial NB':\n",
    "        model = MultinomialNB()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "    \n",
    "    # Train and predict\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Test Size': test_size,\n",
    "        'Accuracy': round(accuracy_score(y_test, y_pred), 4),\n",
    "        'Precision': round(precision_score(y_test, y_pred), 4),\n",
    "        'Recall': round(recall_score(y_test, y_pred), 4),\n",
    "        'F1 Score': round(f1_score(y_test, y_pred), 4),\n",
    "        'Min DF': min_df,\n",
    "        'N-Gram Range': ngram_range,\n",
    "        'Max Features': max_features,\n",
    "        'Confusion Matrix': cm\n",
    "    }\n",
    "\n",
    "# 4. Define Experiment Plan\n",
    "title_split_experiment_plan = [\n",
    "    # Decision Tree\n",
    "    ('Decision Tree', 0.2, (1, 1), 5, 1000),\n",
    "    ('Decision Tree', 0.3, (1, 2), 10, 3000),\n",
    "    ('Decision Tree', 0.4, (1, 3), 15, 2000),\n",
    "    \n",
    "    # k-NN\n",
    "    ('k-NN', 0.2, (1, 1), 5, 1000),\n",
    "    ('k-NN', 0.3, (1, 2), 10, 3000),\n",
    "    ('k-NN', 0.4, (1, 3), 15, 2000),\n",
    "    \n",
    "    # Multinomial NB\n",
    "    ('Multinomial NB', 0.2, (1, 1), 5, 1000),\n",
    "    ('Multinomial NB', 0.3, (1, 2), 10, 3000),\n",
    "    ('Multinomial NB', 0.4, (1, 3), 15, 2000)\n",
    "]\n",
    "\n",
    "# 5. Run Experiments\n",
    "title_split_results = []\n",
    "\n",
    "for model_name, test_size, ngram_range, min_df, max_features in title_split_experiment_plan:\n",
    "    result = run_title_split_experiment(\n",
    "        model_name, test_size, ngram_range, min_df, max_features\n",
    "    )\n",
    "    title_split_results.append(result)\n",
    "\n",
    "# 6. Display Clean Results Table\n",
    "# Separate confusion matrices for plotting\n",
    "confusion_matrices = [res.pop('Confusion Matrix') for res in title_split_results]\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(title_split_results)\n",
    "results_df = results_df.sort_values(by=['Model', 'Test Size'])\n",
    "\n",
    "# Display results table\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 160)\n",
    "display(results_df)\n",
    "\n",
    "# 7. Plot Confusion Matrices\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "\n",
    "for idx, cm in enumerate(confusion_matrices):\n",
    "    row, col = divmod(idx, 3)\n",
    "    ax = axes[row, col]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax)\n",
    "    ax.set_title(f\"{results_df.iloc[idx]['Model']} (Split={results_df.iloc[idx]['Test Size']}, SMOTE)\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4705bc-566a-409f-b3da-27b10ae30404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
