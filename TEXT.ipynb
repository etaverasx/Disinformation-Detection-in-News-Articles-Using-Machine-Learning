{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29ab61f-227c-4d9f-b0ad-eabe29d48d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For text processing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# For data splitting and balancing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# For modeling\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Step 2: Load the cleaned dataset\n",
    "file_path = 'news_articles-1.xlsx'  # If in same directory as your notebook\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Step 3: Quick check\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"First few rows:\")\n",
    "display(df.head())\n",
    "# Step 4: Prepare feature (X) and label (y)\n",
    "X = df['text_without_stopwords']\n",
    "y = df['label'].map({'Fake': 0, 'Real': 1})  # Convert labels to binary: 0 = Fake, 1 = Real\n",
    "\n",
    "# Check class balance\n",
    "print(\"Label distribution:\")\n",
    "print(y.value_counts(normalize=True))\n",
    "# Step 5: Pie chart to show label distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count label frequencies\n",
    "label_counts = y.value_counts()\n",
    "labels = ['Fake News', 'Real News']\n",
    "sizes = label_counts.values\n",
    "colors = ['#ff9999','#66b3ff']\n",
    "explode = (0.05, 0)  # Slightly \"explode\" the first slice (Fake News)\n",
    "\n",
    "# Plot pie chart\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140, colors=colors, explode=explode, shadow=True)\n",
    "plt.title('Fake vs. Real News Distribution')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures the pie is circular\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52debde1-02c9-4c21-8aab-6d59683b031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Controlled Experiment Runner (with Confusion Matrix)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def run_single_experiment(model_name, test_size, ngram_range, min_df, max_features):\n",
    "    lowercase = True\n",
    "    stop_words = 'english'\n",
    "    \n",
    "    # Set up TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        lowercase=lowercase,\n",
    "        stop_words=stop_words,\n",
    "        min_df=min_df,\n",
    "        ngram_range=ngram_range,\n",
    "        max_features=max_features\n",
    "    )\n",
    "    X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "    \n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_tfidf, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Select model\n",
    "    if model_name == 'Decision Tree':\n",
    "        model = DecisionTreeClassifier(random_state=42)\n",
    "    elif model_name == 'k-NN':\n",
    "        model = KNeighborsClassifier()\n",
    "    elif model_name == 'Multinomial NB':\n",
    "        model = MultinomialNB()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model {model_name}\")\n",
    "    \n",
    "    # Train and predict\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Test Size': test_size,\n",
    "        'Accuracy': round(accuracy_score(y_test, y_pred), 4),\n",
    "        'Precision': round(precision_score(y_test, y_pred), 4),\n",
    "        'Recall': round(recall_score(y_test, y_pred), 4),\n",
    "        'F1 Score': round(f1_score(y_test, y_pred), 4),\n",
    "        'Lowercase': lowercase,\n",
    "        'Stop Words': stop_words,\n",
    "        'Min DF': min_df,\n",
    "        'N-Gram Range': ngram_range,\n",
    "        'Max Features': max_features,\n",
    "        'Confusion Matrix': cm  # <== Save confusion matrix here\n",
    "    }\n",
    "\n",
    "# 2. Define Experiments\n",
    "\n",
    "experiment_plan = [\n",
    "    # Decision Tree\n",
    "    ('Decision Tree', 0.2, (1,1), 5, 1000),\n",
    "    ('Decision Tree', 0.3, (1,2), 10, 3000),\n",
    "    ('Decision Tree', 0.4, (1,3), 15, 2000),\n",
    "    \n",
    "    # k-NN\n",
    "    ('k-NN', 0.2, (1,1), 5, 1000),\n",
    "    ('k-NN', 0.3, (1,2), 10, 3000),\n",
    "    ('k-NN', 0.4, (1,3), 15, 2000),\n",
    "    \n",
    "    # Multinomial NB\n",
    "    ('Multinomial NB', 0.2, (1,1), 5, 1000),\n",
    "    ('Multinomial NB', 0.3, (1,2), 10, 3000),\n",
    "    ('Multinomial NB', 0.4, (1,3), 15, 2000)\n",
    "]\n",
    "\n",
    "# 3. Run Experiments\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, test_size, ngram_range, min_df, max_features in experiment_plan:\n",
    "    result = run_single_experiment(\n",
    "        model_name, test_size, ngram_range, min_df, max_features\n",
    "    )\n",
    "    results.append(result)\n",
    "\n",
    "# 4. Display Final Results\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Separate confusion matrices\n",
    "confusion_matrices = [res.pop('Confusion Matrix') for res in results]\n",
    "\n",
    "controlled_results_df = pd.DataFrame(results)\n",
    "controlled_results_df = controlled_results_df.sort_values(by=['Model', 'Test Size'])\n",
    "\n",
    "display(controlled_results_df)\n",
    "\n",
    "\n",
    "# 5. Plot Confusion Matrices\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Quick plot all confusion matrices\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))  # 9 plots (3x3)\n",
    "\n",
    "for idx, cm in enumerate(confusion_matrices):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    ax = axes[row, col]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_title(f\"{controlled_results_df.iloc[idx]['Model']} (Split={controlled_results_df.iloc[idx]['Test Size']})\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a51dc94-5f43-4cb0-8a1d-47150067cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Prepare Data\n",
    "X = df['text_without_stopwords'].astype(str)\n",
    "y = df['label'].map({'Fake': 0, 'Real': 1})\n",
    "\n",
    "\n",
    "# 2. SMOTE Experiment Runner\n",
    "\n",
    "def run_smote_experiment(model_name, test_size, ngram_range, min_df, max_features):\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        stop_words='english',\n",
    "        min_df=min_df,\n",
    "        ngram_range=ngram_range,\n",
    "        max_features=max_features\n",
    "    )\n",
    "    X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_tfidf, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Apply SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Select model\n",
    "    if model_name == 'Decision Tree':\n",
    "        model = DecisionTreeClassifier(random_state=42)\n",
    "    elif model_name == 'k-NN':\n",
    "        model = KNeighborsClassifier()\n",
    "    elif model_name == 'Multinomial NB':\n",
    "        model = MultinomialNB()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "\n",
    "    # Train and predict\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Test Size': test_size,\n",
    "        'Accuracy': round(accuracy_score(y_test, y_pred), 4),\n",
    "        'Precision': round(precision_score(y_test, y_pred), 4),\n",
    "        'Recall': round(recall_score(y_test, y_pred), 4),\n",
    "        'F1 Score': round(f1_score(y_test, y_pred), 4),\n",
    "        'Min DF': min_df,\n",
    "        'N-Gram Range': ngram_range,\n",
    "        'Max Features': max_features,\n",
    "        'Confusion Matrix': cm\n",
    "    }\n",
    "\n",
    "\n",
    "# 3. Define Experiment Plan \n",
    "smote_experiment_plan = [\n",
    "    ('Decision Tree', 0.2, (1,1), 5, 1000),\n",
    "    ('Decision Tree', 0.3, (1,2), 10, 3000),\n",
    "    ('Decision Tree', 0.4, (1,3), 15, 2000),\n",
    "\n",
    "    ('k-NN', 0.2, (1,1), 5, 1000),\n",
    "    ('k-NN', 0.3, (1,2), 10, 3000),\n",
    "    ('k-NN', 0.4, (1,3), 15, 2000),\n",
    "\n",
    "    ('Multinomial NB', 0.2, (1,1), 5, 1000),\n",
    "    ('Multinomial NB', 0.3, (1,2), 10, 3000),\n",
    "    ('Multinomial NB', 0.4, (1,3), 15, 2000)\n",
    "]\n",
    "\n",
    "# 4. Run Experiments\n",
    "smote_results = []\n",
    "\n",
    "for model_name, test_size, ngram_range, min_df, max_features in smote_experiment_plan:\n",
    "    result = run_smote_experiment(\n",
    "        model_name, test_size, ngram_range, min_df, max_features\n",
    "    )\n",
    "    smote_results.append(result)\n",
    "\n",
    "# 5. Display Results and Confusion Matrices\n",
    "# Separate confusion matrices\n",
    "confusion_matrices = [res.pop('Confusion Matrix') for res in smote_results]\n",
    "smote_results_df = pd.DataFrame(smote_results)\n",
    "smote_results_df = smote_results_df.sort_values(by=['Model', 'Test Size'])\n",
    "\n",
    "# Display results\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 160)\n",
    "display(smote_results_df)\n",
    "\n",
    "# Plot confusion matrices\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "\n",
    "for idx, cm in enumerate(confusion_matrices):\n",
    "    row, col = divmod(idx, 3)\n",
    "    ax = axes[row, col]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', cbar=False, ax=ax)\n",
    "    ax.set_title(f\"{smote_results_df.iloc[idx]['Model']} (Split={smote_results_df.iloc[idx]['Test Size']}, SMOTE)\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
